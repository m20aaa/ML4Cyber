{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GAN0G-6jrcpU",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3347e1e-374f-4d00-bd10-93f510c16f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JYfWY6BosKQ6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
        "le = preprocessing.LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q3Kxk8x9sdXj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "data = df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CQ7z-5n9sge9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "X = data[:, 1]\n",
        "y = data[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCIVTx6Ysggm",
        "outputId": "8cefb5b5-a6e3-4260-cd0e-58179d692568",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5572,), (5572,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e7ZpFSZvsgqE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer('\\w+')\n",
        "sw = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KfOsXqgcsgtq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getStem(review):\n",
        "    review = review.lower()\n",
        "    tokens = tokenizer.tokenize(review) # breaking into small words\n",
        "    removed_stopwords = [w for w in tokens if w not in sw]\n",
        "    stemmed_words = [ps.stem(token) for token in removed_stopwords]\n",
        "    clean_review = ' '.join(stemmed_words)\n",
        "    return clean_review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PjtP4dNGsgxj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# get a clean document\n",
        "def getDoc(document):\n",
        "    d = []\n",
        "    for doc in document:\n",
        "        d.append(getStem(doc))\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UiD7bPEfsgo8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "stemmed_doc = getDoc(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6X2GSJXsgmq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "stemmed_doc[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p17dxL_zsgkp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3xEOvVs-s3Uz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# create my vocab\n",
        "vc = cv.fit_transform(stemmed_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jIYvFfTNs5sA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "X = vc.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xSNI8pdjs5uF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SNFPDN0Vs53j",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# NB from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOsrenTNs57y",
        "outputId": "9e0e9bdb-cb30-4f57-e546-0e282371813f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.977705274605764"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(np.asarray(X_train), y_train)\n",
        "model.score(np.asarray(X_test), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n8-Rtl_Ys513",
        "tags": []
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    \"\"\"\n",
        "    Hi Kunal,\n",
        "We invite you to participate in MishMash - Indiaâ€™s largest online diversity hackathon.\n",
        "The hackathon is a Skillenza initiative and sponsored by Microsoft, Unity, Unilever, Gojek, Rocketium and Jharkhand Government.\n",
        "We have a special theme for you - Deep Tech/Machine Learning - sponsored by Unilever, which will be perfect for you.\n",
        "    \"\"\",\n",
        "    \"\"\"Join us today at 12:00 PM ET / 16:00 UTC for a Red Hat DevNation tech talk on AWS Lambda and serverless Java with Bill Burke.\n",
        "Have you ever tried Java on AWS Lambda but found that the cold-start latency and memory usage were far too high?\n",
        "In this session, we will show how we optimized Java for serverless applications by leveraging GraalVM with Quarkus to\n",
        "provide both supersonic startup speed and a subatomic memory footprint.\"\"\",\n",
        "\n",
        "    \"\"\"We really appreciate your interest and wanted to let you know that we have received your application.\n",
        "There is strong competition for jobs at Intel, and we receive many applications. As a result, it may take some time to get back to you.\n",
        "Whether or not this position ends up being a fit, we will keep your information per data retention policies,\n",
        "so we can contact you for other positions that align to your experience and skill set.\n",
        "\"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SvViQfDvs5zX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def prepare(messages):\n",
        "    d = getDoc(messages)\n",
        "    # dont do fit_transform!! it will create new vocab.\n",
        "    return cv.transform(d)\n",
        "messages = prepare(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu76hOSPs5x2",
        "outputId": "17f02ce2-0921-4fa4-c996-afaa96c68206",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham', 'spam', 'ham'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_pred = model.predict(messages)\n",
        "y_pred"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}